{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648c5691",
   "metadata": {
    "id": "648c5691",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<hr style=\"height: 1px;\">\n",
    "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h1>Lesson 10: Bayesian Statistics and Likelihood</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11639ba2",
   "metadata": {
    "id": "11639ba2",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.0 Overview</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02859d6d",
   "metadata": {
    "id": "02859d6d",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<h3>Navigation</h3>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_1\">L10.1 Definition of Convolution</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_1\">L10.1 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_2\">L10.2 Example of Convolutions with Different Functions</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_2\">L10.2 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_3\">L10.3 Prior and Posterior Probabilities and Bayes Theorem</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_3\">L10.3 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_4\">L10.4 Bayesian vs. Frequentist and Likelihood</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_4\">L10.4 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_5\">L10.5 Bayesian vs. Frequentist Fitting Example</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_5\">L10.5 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_10_6\">L10.6 Maximum Likelihood</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_10_6\">L10.6 Exercises</a></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1805bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af1805bb",
    "outputId": "0d16a67c-ccfe-41b3-ab9e-1a5a490167b6",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.0-runcell00\n",
    "\n",
    "#install lmfit if you have not done so\n",
    "!pip install lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34dd39",
   "metadata": {
    "id": "7c34dd39",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.0-runcell01\n",
    "\n",
    "import numpy as np                #https://numpy.org/doc/stable/ \n",
    "import lmfit                      #https://lmfit.github.io/lmfit-py/ \n",
    "import matplotlib.pyplot as plt   #https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html\n",
    "from scipy import stats           #https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd3a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "0afd3a79",
    "outputId": "698acf56-fff9-432e-c4c2-92ef76759f3b",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.0-runcell02\n",
    "\n",
    "#set plot resolution\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#set default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "medium_size = 12\n",
    "large_size = 15\n",
    "\n",
    "plt.rc('font', size=medium_size)          # default text sizes\n",
    "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n",
    "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n",
    "plt.rc('legend', fontsize=medium_size)    # legend\n",
    "plt.rc('axes', titlesize=large_size)      # axes title\n",
    "plt.rc('axes', labelsize=large_size)      # x and y labels\n",
    "plt.rc('figure', titlesize=large_size)    # figure title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856101b",
   "metadata": {
    "id": "0856101b",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.1 Definition of Convolution</h2>  \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_0) | [Exercises](#exercises_10_1) | [Next Section](#section_10_2) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82359e2",
   "metadata": {
    "id": "a82359e2",
    "tags": [
     "learner",
     "py",
     "lect_01",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.1-runcell01\n",
    "\n",
    "#First let's define a triangular distribution\n",
    "def triangle(x,mean=5):\n",
    "    Norm=mean*mean\n",
    "    val=np.where(x <= mean,np.maximum(x,np.zeros(len(x))), np.maximum(2*mean-x,np.zeros(len(x))))\n",
    "    return val/Norm\n",
    "\n",
    "#Now define the gaussian\n",
    "def gaussian(x,mean=0,sigma=1):\n",
    "    return 1./(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mean)**2 / (2 * sigma**2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e216d",
   "metadata": {
    "id": "a70e216d",
    "tags": [
     "learner",
     "py",
     "lect_01",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.1-runcell02\n",
    "\n",
    "#Now let's do a convolution by hand\n",
    "def convolve(f1,f2,x,sigma=1,iMin=-10,iMax=10,iN=2000):\n",
    "    step=(iMax-iMin)/iN\n",
    "    pInt=0\n",
    "    for i0 in range(iN):\n",
    "            pX   = np.repeat(i0*step+iMin,len(x))\n",
    "            pVal = f1(x-pX,sigma=sigma)*f2(pX)\n",
    "            pInt += pVal*step\n",
    "    return pInt\n",
    "\n",
    "#You could consider how the choice of iMin, iMax, and iN affect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e08b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "5e8e08b8",
    "outputId": "96d63fc8-1b97-4c30-be4f-2a19277a42c9",
    "tags": [
     "learner",
     "py",
     "lect_01",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.1-runcell03\n",
    "\n",
    "#now let's plot\n",
    "fig, ax = plt.subplots()\n",
    "x_in=np.linspace(-10, 15, 100)\n",
    "tri_out=triangle(x_in)\n",
    "gaus_out=gaussian(x_in)\n",
    "conv1_out=convolve(gaussian,triangle,x_in)\n",
    "conv2_out=convolve(gaussian,triangle,x_in,sigma=5)\n",
    "\n",
    "ax.plot(x_in,tri_out,label='triangle')\n",
    "ax.plot(x_in,gaus_out,label='gaussian')\n",
    "ax.plot(x_in,conv1_out,label='convolved')\n",
    "ax.plot(x_in,conv2_out,label='convolved($\\sigma=5$)')\n",
    "ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bf38b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "5e8e08b8",
    "outputId": "96d63fc8-1b97-4c30-be4f-2a19277a42c9",
    "tags": [
     "learner",
     "py",
     "lect_01",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.1-runcell04\n",
    "\n",
    "#now let's plot the convolved and original wide Gaussian\n",
    "fig, ax = plt.subplots()\n",
    "x_in=np.linspace(-10, 15, 100)\n",
    "tri_out=triangle(x_in)\n",
    "gaus_out=gaussian(x_in,5,5)\n",
    "conv2_out=convolve(gaussian,triangle,x_in,sigma=5)\n",
    "\n",
    "ax.plot(x_in,tri_out,label='triangle')\n",
    "ax.plot(x_in,gaus_out,label='gaussian')\n",
    "ax.plot(x_in,conv2_out,label='convolved($\\sigma=5$)')\n",
    "ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766a4c3",
   "metadata": {
    "id": "a766a4c3",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_1'></a>     \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_1) | [Next Section](#section_10_2) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd47a6",
   "metadata": {
    "id": "52cd47a6",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.1.1</span>\n",
    "\n",
    "What happens if you convolve a Gaussian with a straight line: $y=x$? Complete the code below to define convolutions for two different values of sigma, using the previously defined functions 'gaussian' and 'convolve'. Then plot in your notebook.\n",
    "\n",
    "Afterwards, consider the following: What happens to the value of the convolved function at $x=0$? What happens if you increase the width of the Gaussian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5bf2c",
   "metadata": {
    "id": "f2b5bf2c",
    "outputId": "86daa2d9-a5e4-4d00-b863-acb25d85077d",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.1.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "#defining a linear function\n",
    "def line(x):\n",
    "    #YOUR CODE HERE\n",
    "    return\n",
    "\n",
    "#creating the convolution\n",
    "x_in=np.linspace(-10, 15, 100) #MUST USE THIS INPUT ARRAY FOR ANSWER CHECKER\n",
    "conv1_out = pass #YOUR CODE HERE, use a gaussian with default mean and sigma\n",
    "conv2_out = pass #YOUR CODE HERE, use a gaussian with default mean and sigma=5\n",
    "\n",
    "\n",
    "#creating plots and comparing to the original functions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "line_out=line(x_in)\n",
    "gaus1_out=gaussian(x_in)\n",
    "\n",
    "ax.plot(x_in,line_out,label='line')\n",
    "ax.plot(x_in,gaus1_out,label='gaussian')\n",
    "ax.plot(x_in,conv1_out,label='convolved')\n",
    "ax.plot(x_in,conv2_out,label='convolved($\\sigma=5$)')\n",
    "ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-m6w2k5PPKoP",
   "metadata": {
    "id": "-m6w2k5PPKoP",
    "tags": [
     "md",
     "learner",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.1.2</span>\n",
    "\n",
    "What happens if you convolve a Gaussian with a Gaussian? Complete the code below to define convolutions for two different values of sigma, again using the previously defined functions 'gaussian' and 'convolve'. Then plot in your notebook.\n",
    "\n",
    "As an extra, consider the following questions:\n",
    "\n",
    "- What is the functional form of the convolution?\n",
    "- What happens to the value of the convolved function at $x=0$?\n",
    "- What happens if you change the width of one or both of the Gaussians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55XJ7UfqPJhe",
   "metadata": {
    "id": "55XJ7UfqPJhe",
    "tags": [
     "py",
     "draft",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.1.2\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "#creating the convolution\n",
    "x_in=np.linspace(-10, 15, 100) #MUST USE THIS INPUT ARRAY FOR ANSWER CHECKER\n",
    "conv1_out = pass #YOUR CODE HERE, use a gaussian with default mean and sigma\n",
    "conv2_out = pass #YOUR CODE HERE, use a gaussian with default mean and sigma=5\n",
    "\n",
    "\n",
    "#creating plots and comparing to the original functions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "gaus1_out=gaussian(x_in)\n",
    "\n",
    "ax.plot(x_in,gaus1_out,label='gaussian')\n",
    "ax.plot(x_in,conv1_out,label='convolved')\n",
    "ax.plot(x_in,conv2_out,label='convolved($\\sigma=5$)')\n",
    "ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe3a84",
   "metadata": {
    "id": "a2fe3a84",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.2 Example of Convolutions with Different Functions</h2>  \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_1) | [Exercises](#exercises_10_2) | [Next Section](#section_10_3) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec3946",
   "metadata": {
    "id": "88ec3946",
    "outputId": "beebc0f8-b24a-456f-a5b3-3f497b4e794c",
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.2-runcell01\n",
    "\n",
    "def func_1(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "#this plots functions with two gaussians of different width\n",
    "def plot_convolutions_with_gaussian(func_in,x,func_name):\n",
    "    func_out=func_in(x)\n",
    "    gaus_out=gaussian(x)\n",
    "    conv1_out=convolve(gaussian,func_in,x)\n",
    "    conv2_out=convolve(gaussian,func_in,x,sigma=2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x,func_out,label=func_name)\n",
    "    ax.plot(x,gaus_out,label='gaussian')\n",
    "    ax.plot(x,conv1_out,label='convolved')\n",
    "    ax.plot(x,conv2_out,label='convolved($\\sigma=2$)')\n",
    "    ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "    ax.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#now let's plot\n",
    "x_in=np.linspace(-10, 15, 100)\n",
    "plot_convolutions_with_gaussian(func_1,x_in,'sin(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c9fa2",
   "metadata": {
    "id": "ed4c9fa2",
    "outputId": "f7ef457a-27ed-4b14-ed7b-aad86dadabe3",
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.2-runcell02\n",
    "\n",
    "def func_2(x):\n",
    "    return np.sin(x)*x\n",
    "\n",
    "\n",
    "#now let's plot\n",
    "x_in=np.linspace(-10, 15, 100)\n",
    "plot_convolutions_with_gaussian(func_2,x_in,'sin(x)*x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2496576",
   "metadata": {
    "id": "e2496576",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_2'></a>     \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_2) | [Next Section](#section_10_3) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fd655",
   "metadata": {
    "id": "e19fd655",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.2.1</span>\n",
    "\n",
    "Often we use convolutions to \"smear\" our distributions analytically, without having to build a simulation. In the code below we sample points from a Gaussian. Take the original function below (a box distribution), add points sampled by a Gaussian, and show that the distribution matches the convolution.\n",
    "\n",
    "Specifically, complete the array `smeared_x_in`, which adds `x_in` and `smeared`. Then complete the array `smeared_box_out`, which takes the average of the smeared values from `func_box` evaluated at the `smeared_x_in` points. Only complete tese arrays in the answer checker, then run the code in your notebook to generate plots.\n",
    "\n",
    "To clearly see that the distributions match, try changing which of `smeared_box_out` and `conv_out` gets plotted first, or just comment out one and then the other. The two should be identical, which means that you only see the one which is plotted second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d171774",
   "metadata": {
    "id": "1d171774",
    "outputId": "3de6dde1-7696-4736-e9b4-30def3ef4ff4",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.2.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "#define a box function\n",
    "def func_box(x):\n",
    "    return 0+0.1*np.where(x < -10,0,1) - 0.1*np.where(x < 10,0,1)\n",
    "\n",
    "lNToys=1000\n",
    "nbins=100\n",
    "sigma=1\n",
    "smeared=np.random.normal(0,sigma,(lNToys,nbins))\n",
    "x_in=np.linspace(-20, 20, nbins)\n",
    "\n",
    "#add the smeared signal to x_in, make 1000 example x distributions from above\n",
    "smeared_x_in=#YOUR CODE HERE\n",
    "\n",
    "#average over 1000 sampled distributions\n",
    "smeared_box_out=#YOUR CODE HERE \n",
    "\n",
    "\n",
    "#PLOT\n",
    "#-------------\n",
    "#now let's plot\n",
    "fig, ax = plt.subplots()\n",
    "x_in=np.linspace(-20, 20, 100)\n",
    "\n",
    "#various functions to add to the final plot\n",
    "box_out=func(x_in)\n",
    "gaus_out=gaussian(x_in)\n",
    "conv_out=convolve(gaussian,func,x_in)\n",
    "\n",
    "#make final plot\n",
    "ax.plot(x_in,box_out,label='box(x)')\n",
    "ax.plot(x_in,smeared_box_out,label='smeared box(x)')\n",
    "ax.plot(x_in,gaus_out,label='gaussian')\n",
    "ax.plot(x_in,conv_out,label='convolved')\n",
    "ax.set(xlabel='x(t)', ylabel='y(t)',title='Convolutions')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81192f8b",
   "metadata": {
    "id": "81192f8b",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.3 Prior and Posterior Probabilities and Bayes Theorem</h2>  \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_2) | [Exercises](#exercises_10_3) | [Next Section](#section_10_4) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f30871",
   "metadata": {
    "id": "a7f30871",
    "outputId": "10c81a22-9086-4425-8d0e-e03396b40e8c",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.3-slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='https://mitx-8s50.github.io/slides/L10/slides_L10_03.html', width=970, height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685db9e5",
   "metadata": {
    "id": "685db9e5",
    "outputId": "563013b0-4daf-4ebd-99c3-68475375215f",
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.3-runcell01\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#Our measurement probability\n",
    "def gaus(mu=0,sigma=1): \n",
    "    x = np.arange(-10, 10, 0.001)\n",
    "    y = stats.norm.pdf(x,mu,sigma)\n",
    "    return x,y\n",
    "\n",
    "#a quick plot of what we expect the measurement to be\n",
    "def plotgaus():\n",
    "    x,y=gaus(0,1)\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    plt.style.use('fast')\n",
    "    ax.plot(x,y)\n",
    "    ax.fill_between(x,y,0, alpha=0.1, color='b')\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    plt.show()\n",
    "\n",
    "plotgaus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c21ec",
   "metadata": {
    "id": "002c21ec",
    "outputId": "b0aebfca-c9d3-40fb-c802-a91d3d700ba0",
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.3-runcell02\n",
    "\n",
    "def gaus(mu=0,sigma=1,meas=2): \n",
    "    x = np.arange(-10, 10, 0.001)\n",
    "    xmeas = np.arange(meas, 10, 0.001)\n",
    "    y = stats.norm.pdf(x,mu,sigma)\n",
    "    ymeas = stats.norm.pdf(xmeas,mu,sigma)\n",
    "    return x,y,xmeas,ymeas\n",
    "\n",
    "def plotgaus():\n",
    "    x,y,xmeas,ymeas=gaus(0,1,2)\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    plt.style.use('fast')\n",
    "    ax.plot(x,y)\n",
    "    ax.fill_between(x,y,0, alpha=0.1, color='b')\n",
    "    ax.fill_between(xmeas,ymeas,0, alpha=0.3, color='b')\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    plt.show()\n",
    "    \n",
    "plotgaus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129dc2b",
   "metadata": {
    "id": "2129dc2b",
    "outputId": "ff16b1bd-60ae-4262-cd6e-58e804e86f0b",
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.3-runcell03\n",
    "\n",
    "np.random.seed(32)\n",
    "\n",
    "def gaus(mu=0,sigma=1): \n",
    "    x = np.arange(-10, 10, 0.001)\n",
    "    y = stats.norm.pdf(x,mu,sigma)\n",
    "    return x,y\n",
    "\n",
    "def plotGausSample(iZ,iSample):\n",
    "    plt.style.use('fast')\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    #sample\n",
    "    samples = np.random.normal(iZ,1,iSample)\n",
    "    x,y=gaus(iZ,1)\n",
    "    #\n",
    "    xs,ys=gaus(0,1)\n",
    "    ax.plot(xs,ys,label='prior')\n",
    "    ax.plot(x,y,label='posterior')\n",
    "    count, bins, ignored = plt.hist(samples, 30, density=True, label=str(iSample)+' samples')\n",
    "    ax.fill_between(xs,ys,0, alpha=0.1)\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotGausSample(2,10)\n",
    "plotGausSample(2,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIR8F_BfdqIF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "BIR8F_BfdqIF",
    "outputId": "aa78035d-b9ff-4aae-ebba-c152d107e8b7",
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.3-runcell04\n",
    "\n",
    "np.random.seed(32)\n",
    "\n",
    "def plotGausSample(iZ,iSample):\n",
    "    plt.style.use('fast')\n",
    "    #sample\n",
    "    samples = np.random.normal(iZ,1,iSample)\n",
    "    x,y=gaus(iZ,1)\n",
    "    #noral st\n",
    "    xs,ys=gaus(0,1)\n",
    "    ys*=100\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.plot(xs,ys,label='prior')\n",
    "    count, bins, ignored = plt.hist(samples, 30, density=True, label=str(iSample)+' samples')\n",
    "    ax.plot(x,y,label='posterior')\n",
    "    ax.fill_between(xs,ys,0, alpha=0.1)\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    ax.legend(loc=2)\n",
    "    #plt.ylim(0,0.43) #note: these bounds are used in video\n",
    "    plt.ylim(0,3.0) #note: these bounds more clearly shows what we are investigating\n",
    "    plt.show()\n",
    "    \n",
    "plotGausSample(2,10)\n",
    "\n",
    "plotGausSample(2,1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db157d",
   "metadata": {
    "id": "c9db157d",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_3'></a>     \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_3) | [Next Section](#section_10_4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3887ca5",
   "metadata": {
    "id": "d3887ca5",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.3.1</span>\n",
    "\n",
    "If you roll a normal die and observe the outcome 6 three times in a row, are you surprised? What is the prior in this case? Enter the value for your prior as a fraction with precision 1e-4.\n",
    "\n",
    "Hint: You could use `stats.binom.pmf` to compute this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2xizPFcQZFD3",
   "metadata": {
    "id": "2xizPFcQZFD3",
    "tags": [
     "py",
     "draft",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.3.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboU7ebvf8D_",
   "metadata": {
    "id": "aboU7ebvf8D_",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.3.2</span>\n",
    "\n",
    "Let's say your prior is a Gaussian with mean 0 and width 1, but your true, posterior distribution is a Gaussian with mean 0.5 and width 1. Generate 1000 events using this posterior distribution and find the most extreme, positive value (farthest from 0). What is the p-value of this extreme value (i.e., the probability of observing this extreme value or higher), given your prior? Enter your answer as a number with precision 1e-6.\n",
    "\n",
    "Given that you have 1000 samples from this posterior distribution, how does this probability compare with what you would expect? In other words, is it likely to have occured once in 1000 samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2-Ff2OQef8D_",
   "metadata": {
    "id": "2-Ff2OQef8D_",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.3.2\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "#use this random seed when calculating/reporting your answers\n",
    "np.random.seed(101)\n",
    "\n",
    "#1000 random samples from posterior distribution\n",
    "sample=#YOUR CODE HERE\n",
    "\n",
    "#most extreme value from samples (take the largest absolute value)\n",
    "exvalue=#YOUR CODE HERE\n",
    "\n",
    "#the probability of attaining that extreme value (or greater), given your prior\n",
    "pvalue=#YOUR CODE HERE\n",
    "\n",
    "#print results\n",
    "print(\"extreme value\",exvalue,\"pvalue\",pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251835bf",
   "metadata": {
    "id": "251835bf",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_4'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.4 Bayesian vs. Frequentist and Likelihood</h2>  \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_3) | [Exercises](#exercises_10_4) | [Next Section](#section_10_5) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50f51c",
   "metadata": {
    "id": "be50f51c",
    "outputId": "d714b17a-e3d9-4d42-e4b2-3e23045a5ac6",
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.4-slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='https://mitx-8s50.github.io/slides/L10/slides_L10_04.html', width=970, height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59db9e",
   "metadata": {
    "id": "ac59db9e",
    "outputId": "8a402ae5-8199-4c46-9e24-fd13152b417d",
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.4-runcell01\n",
    "\n",
    "#Our measurement probability\n",
    "def gaus(mu=0,sigma=1): \n",
    "    x = np.arange(-10, 10, 0.001)\n",
    "    y = stats.norm.pdf(x,mu,sigma)\n",
    "    return x,y\n",
    "\n",
    "def plotGausSampleLike(iZ,iSample):\n",
    "    plt.style.use('fast')\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    #Sample\n",
    "    samples = np.random.normal(iZ,1,iSample)\n",
    "    x,y=gaus(iZ,1)\n",
    "    #prior\n",
    "    xs,ys=gaus(0,1)\n",
    "    #likelihood\n",
    "    yratio=np.minimum(y/(ys*20.),1.)\n",
    "    #plot\n",
    "    ax.plot(xs,ys,label='prior')\n",
    "    ax.plot(x,y,label='posterior')\n",
    "    ax.plot(x,yratio,label='Likelihood/20')\n",
    "    count, bins, ignored = plt.hist(samples, 30, density=True)\n",
    "    ax.fill_between(xs,ys,0, alpha=0.1)\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotGausSampleLike(2,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379f233",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "7379f233",
    "outputId": "e6bb4320-ada7-4f67-b2a0-e8c60665e169",
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.4-runcell02\n",
    "\n",
    "def plotGausSampleLikeNew(iZ,iSample,iSigMax):\n",
    "    plt.style.use('fast')\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    #ample our posterior\n",
    "    samples = np.random.normal(iZ,1,iSample)\n",
    "    x,y=gaus(iZ,1)\n",
    "    #Sample our prior\n",
    "    xs,ys=gaus(0,iSigMax) #######<<<<< This is our tweak\n",
    "    #now compute the likelihood\n",
    "    yratio=np.minimum(0.05*y/ys,20.)\n",
    "    #plot this stuff\n",
    "    ax.plot(xs,ys,label='prior')\n",
    "    ax.plot(x,y,label='posterior')\n",
    "    ax.plot(x,yratio,label='Likelihood/20')\n",
    "    count, bins, ignored = plt.hist(samples, 30, density=True)\n",
    "    ax.fill_between(xs,ys,0, alpha=0.1)\n",
    "    ax.set_xlim([-6,6])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    #now return our sampled normal distribution\n",
    "    return samples\n",
    "    \n",
    "samples=plotGausSampleLikeNew(2,1000,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04556aa",
   "metadata": {
    "id": "d04556aa",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_4'></a>     \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_4) | [Next Section](#section_10_5) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f9e8e",
   "metadata": {
    "id": "729ba31a",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.4.1</span>\n",
    "\n",
    "The choice of prior can really change your outlook on fittings. Here you will compare the likelihood using two different priors.\n",
    "\n",
    "First, plot the maximum likelihood from -5 to 5, using a posterior Gaussian distribution centered at 0.5 and a prior Gaussian distribution centered at 0. Next, use a prior that is a flat distribution, and compare the new likelihood ratio to your previous result. Which prior would be better to use, and why? Choose the best answer from the following:\n",
    "\n",
    "A) Using a Gaussian prior yields a likelihood ratio that is also Gaussian.\\\n",
    "B) Using a Gaussian prior yields a likelihood ratio that is easier to interpret.\\\n",
    "C) Using a flat prior ensures that the likelihood ratio is a contant value.\\\n",
    "D) Using a flat prior ensures that the likelihood ratio does not skyrocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a1e8d",
   "metadata": {
    "id": "e36a1e8d",
    "outputId": "e7aebda7-27c0-4478-95f7-e466a8802059",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.4.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "def flat(iX):\n",
    "    return np.where(iX < 5, np.where(iX < -5, 0, 0.1 ), 0)\n",
    "\n",
    "def plotGausSampleLikeNew2(iPost,iPrior):\n",
    "    plt.style.use('fast')\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    \n",
    "    #Base Posterior a function\n",
    "    x,y=gaus(iPost,1)\n",
    "        \n",
    "    #Gaussian prior\n",
    "    xs,ys = ### Add code here    \n",
    "\n",
    "    #Flat Prior\n",
    "    yflat = ### Add code here    \n",
    "    \n",
    "    #now compute the likelihood ratio\n",
    "    #use 20. as a maximum value\n",
    "    ygaussratio = ### add code here\n",
    "    yflatratio = ### add code here\n",
    "    \n",
    "    #plot this stuff\n",
    "    ax.plot(x,y,label='posterior')\n",
    "    \n",
    "    #plot Gaussian prior and likelihood\n",
    "    ax.plot(xs,ys,label='Gaussian prior')\n",
    "    ax.fill_between(xs,ys,0, alpha=0.1)\n",
    "    ax.plot(x,yratio/20.,label='Gaussian Likelihood/20')\n",
    "    \n",
    "    #plot flat prior and likelihood\n",
    "    ax.plot(x,yflat,label='Flat prior')\n",
    "    ax.plot(x,yflatratio/20.,label='Flat Likelihood/20')\n",
    "    \n",
    "    ax.set_xlim([-5,5])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('p')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    #now return our sampled normal distribution\n",
    "    return samples\n",
    "    \n",
    "samples=plotGausSampleLikeNew2(2,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44603f5d",
   "metadata": {
    "id": "729ba31a",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.4.2</span>\n",
    "\n",
    "Now let's calculate the likelihood ratio for the maximum value obtained from simulated data, where the data are randomly drawn from a Gaussian distribution with mean=0.25 and sigma=1. We will use a Gaussian prior with mean=0 and sigma=1. \n",
    "\n",
    "First, complete the code, which should do the following: the `maxlikelihood` function should calculate the likelihood ratio between two Gaussian distributions (posterior/prior), evaluated at the value `val`, where `val` is the maximum value obtained from the randomly sampled array`isamples`. In the function `maxlike`, the array `samples` is drawn from a Gaussian distribution with mean=0.25 and sigma=1, and `plotGausSampleLikeNew` is used to obtain the data and make the plots.\n",
    "\n",
    "After completing the code, compare the output of `maxlike` using 1e2 samples and 1e6 samples. What is the maximum likelihood value in each case? Would you expect it to increase or decrease with more samples? What does this mean about the distributions (do we have the right prior)?\n",
    "\n",
    "Report your answer as a list of two numbers with precition 1e-2: `[max likelihood 1e2 samples, max likelihood 1e6 samples]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a46e15",
   "metadata": {
    "id": "3784c760",
    "outputId": "da0a7e7b-7fe5-452b-a85b-803c51eda779",
    "tags": [
     "learner",
     "learner_chopped",
     "draft"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.4.2\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "def maxlikelihood(isamples,mu1=0.25,sig1=1,mu2=0,sig2=1):\n",
    "    val=np.max(isamples)#compute the highest sampled gaussian\n",
    "    #now compute the likelihood of these two\n",
    "    like=#YOUR CODE HERE\n",
    "    return like\n",
    "\n",
    "def maxlike(iN):\n",
    "    samples=plotGausSampleLikeNew(0.25,iN,1)\n",
    "    like=maxlikelihood(samples)\n",
    "    print(\"Max likelihood:\",iN,\" is \",like)\n",
    "\n",
    "maxlike(100)\n",
    "maxlike(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14e017",
   "metadata": {
    "id": "3a14e017",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_5'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.5 Bayesian vs. Frequentist Fitting Example</h2>  \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_4) | [Exercises](#exercises_10_5) | [Next Section](#section_10_6) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a605327",
   "metadata": {
    "id": "2a605327",
    "outputId": "033b4b9b-0a28-4157-c11c-7d8860700785",
    "tags": [
     "learner",
     "py",
     "lect_05",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.5-runcell01\n",
    "\n",
    "#with Bayesian, we hypothesize a Gaussian and fit it\n",
    "from lmfit.models import GaussianModel\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#randomly sample 100 events from a Gaussian\n",
    "lN=100\n",
    "samples = np.random.normal(0,1,lN)\n",
    "#make a histogram\n",
    "count, bins, ignored = plt.hist(samples,30)\n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "#poisson unc.\n",
    "weight=1./np.sqrt(count)\n",
    "weight[weight==float('+inf')] = 0\n",
    "plt.show()\n",
    "\n",
    "#Now we can consider two ways to interpret the data\n",
    "def frequentist(iBins,iCount,weight): #fit a Gaussian floating all parameters\n",
    "    model = GaussianModel()\n",
    "    params = model.make_params(center=2, amplitude=1, sigma=1) \n",
    "    result = model.fit(iCount, params, x=iBins,weights=weight)\n",
    "    result.plot()\n",
    "    print(result.fit_report())\n",
    "    \n",
    "\n",
    "frequentist(binscenters,count,weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df976a40",
   "metadata": {
    "id": "2a605327",
    "outputId": "033b4b9b-0a28-4157-c11c-7d8860700785",
    "tags": [
     "learner",
     "py",
     "lect_05",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.5-runcell02\n",
    "\n",
    "np.random.seed(42)\n",
    "    \n",
    "def bayesianBad(iBins,iCount,weight):#fit a gaussian fix the mean and sgima\n",
    "    model = GaussianModel()\n",
    "    params = model.make_params(center=2, amplitude=1, sigma=1) \n",
    "    params['center'].vary=False\n",
    "    params['sigma'].vary=False\n",
    "    result = model.fit(iCount, params, x=iBins,weights=weight)\n",
    "    result.plot()\n",
    "    print(result.fit_report())\n",
    "\n",
    "bayesianBad(binscenters,count,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c658423",
   "metadata": {
    "id": "7c658423",
    "outputId": "cf2055f2-4940-41c6-b083-e6b1908c3958",
    "tags": [
     "learner",
     "py",
     "lect_05",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.5-runcell03\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import lmfit\n",
    "#here is our modified function\n",
    "def gauss(x, amp, mu, sigma,dmu):\n",
    "    return amp * np.exp(-(x-mu+dmu)**2 / (2.*sigma**2))\n",
    "\n",
    "#now we define our loss we want to minimize\n",
    "def resid(params, x, ydata,weights):\n",
    "    mu    = params['center'].value\n",
    "    sigma = params['sigma'].value\n",
    "    amp   = params['amplitude'].value\n",
    "    dmu   = params['deltamu'].value\n",
    "    lossshift=0\n",
    "    if abs(dmu) > 3:\n",
    "        lossshift=1e32\n",
    "    y_model= gauss(x,amp,mu,sigma,dmu)\n",
    "    residarr = (y_model - ydata)*weights\n",
    "    #now append our constraint to the loss\n",
    "    residarr = np.append(residarr,lossshift)\n",
    "    return residarr\n",
    "    \n",
    "def bayesianGood(iBins,iCount,weights,initial=2):\n",
    "    model = GaussianModel()\n",
    "    params = model.make_params(center=initial, amplitude=1, sigma=1) \n",
    "    params['center'].vary=False\n",
    "    params['sigma'].vary=False\n",
    "    params.add(\"deltamu\", value=0.0, min=-10, max=10) #Our new line of code\n",
    "    result = lmfit.minimize(resid, params, args=(iBins, iCount,weights))\n",
    "    lmfit.report_fit(result)\n",
    "    #Now we plot it. \n",
    "    plt.errorbar(iBins, iCount,np.sqrt(iCount), lw=2,fmt=\".k\", capsize=0)\n",
    "    plt.plot(binscenters,gauss(binscenters,result.params['amplitude'].value,result.params['center'].value,result.params['sigma'].value,result.params['deltamu'].value))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"p\")\n",
    "    plt.show()\n",
    "\n",
    "bayesianGood(binscenters,count,weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce12f3",
   "metadata": {
    "id": "92ce12f3",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_5'></a>     \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_5) | [Next Section](#section_10_6) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b83f34",
   "metadata": {
    "id": "77b83f34",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.5.1</span>\n",
    "\n",
    "Run the above Bayesian good fit, centering the mean at an incorrect value of 1 and then the correct value 0 (this can be set using the `initial` parameter in the function).\n",
    "\n",
    "What is the bias on mu (i.e., `deltamu`) in each case? Is it significant? Report your answer as a list of two numbers with precision 1e-2: `[deltamu1, deltamu0]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25076",
   "metadata": {
    "id": "26e25076",
    "outputId": "001a283e-4e4a-4706-970b-e270cdce3749",
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L10.5.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "np.random.seed(42)\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88302269",
   "metadata": {
    "id": "88302269",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_10_6'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L10.6 Maximum Likelihood</h2>     \n",
    "\n",
    "| [Top](#section_10_0) | [Previous Section](#section_10_5) | [Exercises](#exercises_10_6) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a1ffa",
   "metadata": {
    "id": "567a1ffa",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_10_6'></a>   \n",
    "\n",
    "| [Top](#section_10_0) | [Restart Section](#section_10_6) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83a929",
   "metadata": {
    "id": "db83a929",
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-10.6.1</span>\n",
    "\n",
    "Which of the following statements best explains why we maximize the likelihood function in statistical inference?\n",
    "\n",
    "A) To obtain estimates of unknown parameters based on observed data\\\n",
    "B) To minimize the sum of squared errors between the predicted and actual values\\\n",
    "C) To test the hypothesis that the data was generated by a particular model\\\n",
    "D) To calculate the mean and variance of the data\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
