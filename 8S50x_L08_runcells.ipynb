{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802238db",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<hr style=\"height: 1px;\">\n",
    "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h1>Lesson 8: Fitting Neutrino Data</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348d65b",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_8_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.0 Overview</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dfdd9",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<h3>Navigation</h3>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_1\">L8.1 Neutrino Oscillations</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_1\">L8.1 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_2\">L8.2 Loading the Data</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_2\">L8.2 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_3\">L8.3 Fitting the Master Function to the Data</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_3\">L8.3 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_4\">L8.4 Principal Component Analysis</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_4\">L8.4 Exercises</a></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab603bc7",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<h3>Importing Data (Colab Only)</h3>\n",
    "\n",
    "If you are in a Google Colab environment, run the cell below to import the data for this notebook. Otherwise, if you have downloaded the course repository, you do not have to run the cell below.\n",
    "\n",
    "See the source and attribution information below:\n",
    "\n",
    ">data: data/L08/NOvA_2020_data_histograms.root, data/L08/NOvA_2020_data_release_predictions_with_systs_all_hists.root <br>\n",
    ">source: https://publicdocs.fnal.gov/cgi-bin/ShowDocument?docid=17, https://doi.org/10.1103/PhysRevD.106.032004 <br>\n",
    ">attribution: M.â€‰A. Acero et al. (The NOvA Collaboration), Phys. Rev. D 106, 032004 <br>\n",
    ">license type: Public document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b451aa5",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.0-runcell00\n",
    "\n",
    "#importing data from git repository\n",
    "\n",
    "!git init\n",
    "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n",
    "!git config core.sparseCheckout true\n",
    "!echo 'data/L08' >> .git/info/sparse-checkout\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11924b",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.0-runcell01\n",
    "\n",
    "# for Colab users\n",
    "!pip install lmfit\n",
    "!pip install uproot\n",
    "!pip install astroML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b6f96",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.0-runcell02\n",
    "\n",
    "import numpy as np                 #https://numpy.org/doc/stable/\n",
    "from scipy import optimize as opt  #https://docs.scipy.org/doc/scipy/reference/optimize.html\n",
    "import matplotlib.pyplot as plt    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "import lmfit                       #https://lmfit.github.io/lmfit-py/ \n",
    "import scipy.stats as stats        #https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "import uproot                      #https://uproot.readthedocs.io/en/latest/\n",
    "from sklearn.decomposition import PCA                   #https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "from sklearn.datasets import fetch_lfw_people           #https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html\n",
    "from sklearn.decomposition import PCA as RandomizedPCA  \n",
    "from astroML.datasets import sdss_corrected_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176308a",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.0-runcell03\n",
    "\n",
    "#set plot resolution\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#set default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "medium_size = 12\n",
    "large_size = 15\n",
    "\n",
    "plt.rc('font', size=medium_size)          # default text sizes\n",
    "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n",
    "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n",
    "plt.rc('legend', fontsize=medium_size)    # legend\n",
    "plt.rc('axes', titlesize=large_size)      # axes title\n",
    "plt.rc('axes', labelsize=large_size)      # x and y labels\n",
    "plt.rc('figure', titlesize=large_size)    # figure title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98847c2",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_8_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.1 Neutrino Oscillations</h2>  \n",
    "\n",
    "| [Top](#section_8_0) | [Previous Section](#section_8_0) | [Exercises](#exercises_8_1) | [Next Section](#section_8_2) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd95cf",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.1-slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='https://mitx-8s50.github.io/slides/L08/slides_L08_01.html', width=970, height=550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58d903",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-8.1.1</span>\n",
    "\n",
    "For a neutrino beam that has a detector 1000km away, like is present with the DUNE neutrino experiment, what is the optimal energy (in GeV) to observe muon neutrino disappearance given a neutrino energy > 0.5 GeV?\n",
    "\n",
    "Use the master formula in the code cell below, which outputs the probability of oscillating from a muon neutrino to a muon neutrino, as a function of energy (in units of GeV). Find the minimum of the function to determine where the muon neutrino disappears.\n",
    "\n",
    "Enter your answer as a number with precision 1e-2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911ae4b",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L8.1.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "def master_formula(E):\n",
    "    deltam=1*1e-3\n",
    "    L=1000\n",
    "    sin2theta23=0.57\n",
    "    xval=1.27*deltam*scale1*L/E\n",
    "    #val=1-4*scale2*sin2theta23*(1-scale2*sin2theta23)*np.sin(xval)**2\n",
    "    val=1-4*sin2theta23*(1-sin2theta23)*(np.sin(xval)**2)\n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b727f3a",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_8_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.2 Loading the Data</h2>  \n",
    "\n",
    "| [Top](#section_8_0) | [Previous Section](#section_8_1) | [Exercises](#exercises_8_2) | [Next Section](#section_8_3) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7586f0",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.2-runcell01\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import uproot\n",
    "\n",
    "file = uproot.open(\"data/L08/NOvA_2020_data_histograms.root\")\n",
    "\n",
    "#print(file.classnames())\n",
    "\n",
    "def plot(iLabel,iFile,iColor):\n",
    "    bin_edges = iFile[iLabel].axis().edges()\n",
    "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n",
    "    plt.xlabel(\"E (GeV)\")\n",
    "    plt.ylabel(\"$N_{events}$\")\n",
    "    plt.errorbar(bin_centers,iFile[iLabel].values(),yerr=iFile[iLabel].errors(),marker='.',linestyle = '', color = iColor,label=iLabel)    \n",
    "    \n",
    "plot(\"neutrino_mode_numu_quartile1\",file,'black')\n",
    "plot(\"antineutrino_mode_numu_quartile1\",file,'red')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2131",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.2-runcell02\n",
    "\n",
    "filePred = uproot.open(\"data/L08/NOvA_2020_data_release_predictions_with_systs_all_hists.root\")\n",
    "\n",
    "#print(filePred.classnames())\n",
    "plot(\"prediction_components_numu_fhc_Quartile1/NoOscillations_Total_pred\",filePred,'black')\n",
    "plot(\"prediction_components_numu_rhc_Quartile1/NoOscillations_Total_pred\",filePred,'red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506d164",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.2-runcell03\n",
    "\n",
    "nquartiles=4\n",
    "label=\"neutrino_mode_numu_quartile\"\n",
    "predlabel0=\"prediction_components_numu_fhc_Quartile\"\n",
    "predlabel1=\"/NoOscillations_Total_pred\"\n",
    "bin_edges=file[label+\"1\"].axis().edges()\n",
    "x = 0.5*(bin_edges[1:] + bin_edges[:-1])\n",
    "def ratio(iQuartile,iPlot=False):\n",
    "    ytop=file[label+str(i0+1)].values()\n",
    "    ytop_err=file[label+str(i0+1)].values()\n",
    "    ybot=filePred[predlabel0+str(i0+1)+predlabel1].values()\n",
    "    #ybot_err=file[label+str(i0+1)].values() we will skip this since the error is much smaller\n",
    "    y = ytop/ybot\n",
    "    y_err = ytop_err/ybot #we will ignore the ybot error since it is tiny\n",
    "    if iPlot:\n",
    "        plt.errorbar(x,y,yerr=y_err,marker='.',linestyle = '',label=\"Quartile \"+str(i0+1))\n",
    "    return y,y_err\n",
    "    \n",
    "for i0 in range(nquartiles):\n",
    "    ratio(i0,True)\n",
    "    \n",
    "plt.xlabel(\"E(GeV)\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd4ba8",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_02",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.2-runcell04\n",
    "\n",
    "def combinedRatio():\n",
    "    y,y_err = ratio(0,False)\n",
    "    y_arrs=np.array([y])\n",
    "    weight_arrs=np.array([y_err])\n",
    "    for i0 in range(nquartiles-1):\n",
    "        y,y_err = ratio(i0,False)\n",
    "        y_arrs=np.vstack([y_arrs,y])\n",
    "        weights=1./(y_err**2)\n",
    "        weights[weights == np.inf] = 0.1\n",
    "        weight_arrs = np.vstack([weight_arrs,weights])\n",
    "    #Now do the weighted \n",
    "    yout=np.average(y_arrs,weights=weight_arrs,axis=0)\n",
    "    weights=np.sum(weight_arrs,axis=0)\n",
    "    return yout,1/weights**0.5,weights**0.5\n",
    "\n",
    "label=\"neutrino_mode_numu_quartile\"\n",
    "predlabel0=\"prediction_components_numu_fhc_Quartile\"\n",
    "y,yerr,weights=combinedRatio()    \n",
    "\n",
    "label=\"antineutrino_mode_numu_quartile\"\n",
    "predlabel0=\"prediction_components_numu_rhc_Quartile\"\n",
    "y_anti,yerr_anti,weights_anti=combinedRatio()    \n",
    "\n",
    "plt.errorbar(x,y,yerr=yerr,marker='.',linestyle = '',label=\"neutrino\")\n",
    "plt.errorbar(x,y_anti,yerr=yerr_anti,marker='.',linestyle = '',label=\"anti-neutrino\")\n",
    "plt.xlabel(\"E(GeV)\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8542f60",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_8_2'></a>     \n",
    "\n",
    "| [Top](#section_8_0) | [Restart Section](#section_8_2) | [Next Section](#section_8_3) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e8f87",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-8.2.1</span>\n",
    "\n",
    "In this problem, we want to show that the weighted average with weight given by $\\frac{1}{\\sigma^2}$ minmizes the uncertainty. For this case, consider a weighted average of two numbers $x$ and $y$. We can define the weighted average $\\bar{x}$ as \n",
    "\n",
    "$$\\bar{x}=f x + (1-f) y$$\n",
    "\n",
    "where $0 \\geq f \\geq 1$ is our weight factor. The uncertainty on $\\bar{x}$ can be written as \n",
    "\n",
    "\n",
    "$$\\sigma^2_{\\bar{x}}=f^2 \\sigma_{x}^2 + (1-f)^2 \\sigma_{y}^2$$ \n",
    "\n",
    "To minimize the uncertainty all we need to do is \n",
    "\n",
    "$$ \\frac{d\\sigma_{\\bar{x}}^2}{df} = 0$$\n",
    "\n",
    "What is the value of $f$ that minimizes the uncertainty? Express your answer using `sigmax` for $\\sigma_{x}$ and `sigmay` for $\\sigma_{y}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51599a46",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_8_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.3 Fitting the Master Function to the Data</h2>  \n",
    "\n",
    "| [Top](#section_8_0) | [Previous Section](#section_8_2) | [Exercises](#exercises_8_3) | [Next Section](#section_8_4) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147b619",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='https://mitx-8s50.github.io/slides/L08/slides_L08_03.html', width=970, height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789833e8",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell01\n",
    "\n",
    "import lmfit\n",
    "deltam=1*1e-3\n",
    "L=810\n",
    "sin2theta23=1.0\n",
    "def func(x,scale1,scale2):\n",
    "    xval=1.27*deltam*scale1*L/x\n",
    "    #val=1-4*scale2*sin2theta23*(1-scale2*sin2theta23)*np.sin(xval)**2\n",
    "    val=1-4*scale2*(1-scale2)*(np.sin(xval)**2)\n",
    "    return val\n",
    "\n",
    "def fit(iX,iY,iWeight):\n",
    "    model  = lmfit.Model(func)\n",
    "    p = model.make_params(scale1=1.0,scale2=0.6)\n",
    "    result = model.fit(x=iX[iY > 0],data=iY[iY > 0], params=p, weights=iWeight[iY > 0])\n",
    "    lmfit.report_fit(result)\n",
    "    result.plot()\n",
    "    print(\"Fit1 chi2 probability: \",stats.chi2.cdf(result.chisqr,result.nfree))\n",
    "\n",
    "fit(x,y,weights)\n",
    "fit(x,y_anti,weights_anti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcfd65",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell02\n",
    "\n",
    "def twoLogLike(var,iX=x,iY=y,iWeights=weights):\n",
    "    lTot=0\n",
    "    xtest=func(iX,var[1],var[0])\n",
    "    lTot = weights*(iY-xtest)\n",
    "    return np.sum(lTot**2)\n",
    "\n",
    "from scipy import optimize as opt\n",
    "x0 = np.array([1,1])\n",
    "sol=opt.minimize(twoLogLike, x0)\n",
    "\n",
    "def plotScan(sol):\n",
    "    #Look the same answers, now let's plot the chi2\n",
    "    xscan = np.linspace(sol.x[0]*0.6,sol.x[0]*2.5, 100)\n",
    "    yscan = np.linspace(sol.x[1]*0.6,sol.x[1]*2.0, 100)\n",
    "    X, Y = np.meshgrid(xscan, yscan)\n",
    "    levels = [0.1,1,2.3,4,9, 16, 25, 36, 49, 64, 81, 100]\n",
    "    for i0 in range(len(levels)):\n",
    "        levels[i0] = levels[i0]+sol.fun\n",
    "    Z = np.array([twoLogLike([xscan,yscan]) for (xscan,yscan) in zip(X.ravel(), Y.ravel())]).reshape(X.shape)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    c = ax.pcolor(X,Y,Z,cmap='RdBu')\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    c = plt.contour(X, Y, Z, levels,colors=['red', 'blue', 'yellow','green'])\n",
    "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n",
    "    plt.ylabel(\"$\\Delta m^{2}_{23}$\")\n",
    "    plt.show()\n",
    "\n",
    "plotScan(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e57ac",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell03\n",
    "\n",
    "#Now let's fix one parameter at the minimum, and profile the other\n",
    "def scanAxes(sol):\n",
    "    xscan = np.linspace(sol.x[0]*0.8,sol.x[0]*2.2, 100)\n",
    "    yscan = np.linspace(sol.x[1]*0.8,sol.x[1]*1.2, 100)\n",
    "\n",
    "    xLog = np.array([])\n",
    "    for pX in xscan:\n",
    "        xLog = np.append(xLog,twoLogLike(var=[pX,sol.x[1]]))\n",
    "\n",
    "    yLog = np.array([])\n",
    "    for pY in yscan:\n",
    "        yLog = np.append(yLog,twoLogLike(var=[sol.x[0],pY]))\n",
    "\n",
    "    plt.plot(xscan, xLog,label='loglike');\n",
    "    plt.axhline(sol.fun+1, c='red')\n",
    "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n",
    "    plt.ylabel(\"2$\\Delta$LL\")\n",
    "    plt.show()\n",
    "\n",
    "    #Now for the other parameter\n",
    "    plt.plot(yscan,yLog,label='LL');\n",
    "    plt.axhline(sol.fun+1, c='red')\n",
    "    plt.xlabel(\"$\\Delta m^{2}_{23}$\")\n",
    "    plt.ylabel(\"2$\\Delta$LL\")\n",
    "    plt.show()\n",
    "    \n",
    "scanAxes(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37605587",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell04\n",
    "\n",
    "#answer\n",
    "def twoLogLike(var,iX=x,iY=y_anti,iWeights=weights_anti):\n",
    "    lTot=0\n",
    "    xtest=func(iX,var[1],var[0])\n",
    "    lTot = weights*(iY-xtest)\n",
    "    return np.sum(lTot**2)\n",
    "\n",
    "x0 = np.array([1,1])\n",
    "sol=opt.minimize(twoLogLike, x0)\n",
    "plotScan(sol)\n",
    "scanAxes(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad2eca",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell05\n",
    "\n",
    "#Now what if we try to add the world's measurement of these parameters into our fit\n",
    "#https://pdg.lbl.gov/2020/listings/rpp2020-list-neutrino-mixing.pdf\n",
    "def twoLogLike(var,iX=x,iY=y,iWeights=weights):\n",
    "    lTot=0\n",
    "    xtest=func(iX,var[1],var[0])\n",
    "    lTot = weights*(iY-xtest)\n",
    "    lTot = np.sum(lTot**2)\n",
    "    sin2worldavg=0.547\n",
    "    sin2uncavg=0.021\n",
    "    constraintsin2=((var[0]-sin2worldavg)**2)/(sin2uncavg**2)\n",
    "    deltamworldavg=2.453\n",
    "    deltamuncavg=0.034\n",
    "    constraintdeltam=((var[1]-deltamworldavg)**2)/(deltamuncavg**2)\n",
    "    return lTot+constraintsin2+constraintdeltam\n",
    "\n",
    "x0 = np.array([1,1])\n",
    "sol=opt.minimize(twoLogLike, x0)\n",
    "plotScan(sol)\n",
    "scanAxes(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23420b84",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_03",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.3-runcell06\n",
    "\n",
    "def scanAxes(sol):\n",
    "    xscan = np.linspace(sol.x[0]*0.9,sol.x[0]*1.2, 100)\n",
    "    yscan = np.linspace(sol.x[1]*0.9,sol.x[1]*1.1, 100)\n",
    "\n",
    "    xLog = np.array([])\n",
    "    for pX in xscan:\n",
    "        xLog = np.append(xLog,twoLogLike(var=[pX,sol.x[1]]))\n",
    "\n",
    "    yLog = np.array([])\n",
    "    for pY in yscan:\n",
    "        yLog = np.append(yLog,twoLogLike(var=[sol.x[0],pY]))\n",
    "\n",
    "    plt.plot(xscan, xLog,label='loglike');\n",
    "    plt.axhline(sol.fun+1, c='red')\n",
    "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n",
    "    plt.ylabel(\"2$\\Delta$LL\")\n",
    "    plt.show()\n",
    "\n",
    "    #Now for the other parameter\n",
    "    plt.plot(yscan,yLog,label='LL');\n",
    "    plt.axhline(sol.fun+1, c='red')\n",
    "    plt.xlabel(\"$\\Delta m^{2}_{23}$\")\n",
    "    plt.ylabel(\"2$\\Delta$LL\")\n",
    "    plt.show()\n",
    "    \n",
    "scanAxes(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acadc6",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_8_3'></a>     \n",
    "\n",
    "| [Top](#section_8_0) | [Restart Section](#section_8_3) | [Next Section](#section_8_4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948684e",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-8.3.1</span>\n",
    "\n",
    "Looking at the world's best fit values, does the NOvA data improve the best fit and, if so, by how much? Does this improvement make sense? Choose from the options below (optionally draft a computational solution):\n",
    "\n",
    "- The uncertainty gets better in m23 and sin2theta23. \n",
    "- The uncertainty gets better in m23, but worse in sin2theta23. \n",
    "- The uncertainty gets worse in m23, but better in sin2theta23. \n",
    "- The uncertainty gets worse in m23 and sin2theta23. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2651a68",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L8.3.1\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c73eca",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='section_8_4'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.4 Principal Component Analysis</h2>     \n",
    "\n",
    "| [Top](#section_8_0) | [Previous Section](#section_8_3) | [Exercises](#exercises_8_4) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd59fa6",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.4-runcell01\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy.linalg as la\n",
    "#make some toy data\n",
    "lAs = np.random.normal(0,1,1000)\n",
    "lBs = np.random.normal(0,1,1000)+0.5*lAs\n",
    "cov = np.cov([lAs,lBs])\n",
    "#eigen cov\n",
    "w, v=la.eig(cov)\n",
    "\n",
    "\n",
    "plt.plot(lAs,lBs,\".\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "X=(np.vstack([lAs,lBs])).T\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print(\"PCA vectors\")\n",
    "print(pca.components_)\n",
    "print(\"PCA values\")\n",
    "print(pca.explained_variance_)\n",
    "print(\"Old Eigen\",\"vectors\",w,\"values\",v)\n",
    "\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',linewidth=2,shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(lAs, lBs, alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05851adf",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.4-runcell02\n",
    "\n",
    "#Now let's do it ML style for fun\n",
    "#Load some images of faces\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "#Let's plot the eigenvectors\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(faces.data[i].reshape(62, 47), cmap='bone')\n",
    "    \n",
    "#Fit them to PCA \n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "pca = RandomizedPCA(200)\n",
    "pca.fit(faces.data)\n",
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "#Let's plot the eigenvectors\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7d1e7",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.4-runcell03\n",
    "\n",
    "# Compute the components and projected faces\n",
    "pca = RandomizedPCA(80).fit(faces.data)\n",
    "components = pca.transform(faces.data)\n",
    "projected = pca.inverse_transform(components)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('80-dim\\nreconstruction');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83deda61",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "lect_04",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L8.4-runcell04\n",
    "\n",
    "from astroML.datasets import sdss_corrected_spectra\n",
    "\n",
    "data = sdss_corrected_spectra.fetch_sdss_corrected_spectra()\n",
    "wavelengths = sdss_corrected_spectra.compute_wavelengths(data)\n",
    "spectra_raw = data['spectra']\n",
    "count=-1\n",
    "#let's plot this guy\n",
    "fig, ax = plt.subplots(2, 10, figsize=(20, 5.5),subplot_kw={'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "nrows = 2; ncols = 10\n",
    "for i in range(ncols):\n",
    "    for j in range(nrows):\n",
    "        count=count+1\n",
    "        ax[j,i].plot(wavelengths,spectra_raw[count], '-k', lw=1)\n",
    "        ax[j,i].set_xlim(3100, 7999)\n",
    "        if j < nrows - 1:\n",
    "            ax[j,i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        else:\n",
    "            ax[j,i].set_xlabel(r'wavelength $(\\AA)$')\n",
    "            \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039b9bd",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "<a name='exercises_8_4'></a>   \n",
    "\n",
    "| [Top](#section_8_0) | [Restart Section](#section_8_4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a15f0",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-8.4.1</span>\n",
    "\n",
    "Your task is to run PCA, look at the dominant eigenvector, and find the top two spectral lines. What do they correspond to (refer to the table <a href=\"http://astronomy.nmsu.edu/drewski/tableofemissionlines.html\" target=\"_blank\">here</a>.)?\n",
    "\n",
    "Select two spectral lines from the options below (in units of angstroms):\n",
    "\n",
    "- He ~4200\n",
    "- H$\\gamma$ ~4350\n",
    "- H$\\beta$ ~4860\n",
    "- O III ~4950\n",
    "- O III ~5006\n",
    "- H$\\alpha$ ~6560\n",
    "- N II ~6580\n",
    "- O I ~7000\n",
    "\n",
    "Does this make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f135894",
   "metadata": {
    "tags": [
     "draft",
     "py",
     "learner_chopped"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>EXERCISE: L8.4.1\n",
    "\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "from astroML.datasets import sdss_corrected_spectra\n",
    "\n",
    "data = sdss_corrected_spectra.fetch_sdss_corrected_spectra()\n",
    "wavelengths = sdss_corrected_spectra.compute_wavelengths(data)\n",
    "spectra_raw = data['spectra']\n",
    "\n",
    "#select only the first 850 bins to avoid noise features\n",
    "spectra_raw = spectra_raw[:,0:850]\n",
    "wavelengths = wavelengths[0:850]\n",
    "pca = RandomizedPCA()\n",
    "\n",
    "\n",
    "#YOUR CODE HERE\n",
    "#fit the pca to the spectra_raw data \n",
    "#plot the first eigenvector, pca.components_[0] over the full range of wavelengths\n",
    "#optionally constrain the wavelength range to zoom in on spectral lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fa5ae",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "learner_chopped"
    ]
   },
   "source": [
    ">#### Follow-up 8.4.1a (ungraded)\n",
    ">\n",
    ">Plot all of the eigenvectors. What are the dominant features of each?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
